{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append(os.getenv('SPARSE_PROBING_ROOT'))\n",
    "from activations.activation_subset import load_activation_subset\n",
    "from load import load_feature_dataset, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_property = 'sex_or_gender'\n",
    "n_seq = 20\n",
    "\n",
    "# wikidata_property = 'occupation_athlete'\n",
    "# n_seq = 5\n",
    "\n",
    "model = 'pythia-70m'\n",
    "model = 'pythia-1b'\n",
    "model = 'pythia-6.9b'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'name', 'class', 'mapped_class', 'tokens', 'logit_index'],\n",
       "    num_rows: 20\n",
       "})"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset_name = f'wikidata_ablations_{wikidata_property}.pyth.128.{n_seq}'\n",
    "dataset = load_feature_dataset(os.path.join('ablation_datasets', dataset_name))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1)]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the logits\n",
    "data_dir = os.path.join(\n",
    "    os.getenv('RESULTS_DIR'),\n",
    "    'ablations',\n",
    "    model,\n",
    "    'ablation_datasets',\n",
    "    dataset_name,\n",
    "    )\n",
    "data_files = os.listdir(data_dir)\n",
    "\n",
    "nominal_logits = torch.load(os.path.join(data_dir, 'nominal_logits.pt'))\n",
    "\n",
    "ablated_logits = {}\n",
    "for data_file in data_files:\n",
    "    if 'ablated_logits' not in data_file:\n",
    "        continue\n",
    "\n",
    "    lix, nix = re.match('ablated_logits_(\\d+)_(\\d+).pt', data_file).groups()\n",
    "    neuron = (int(lix), int(nix))\n",
    "\n",
    "    ablated_logits[neuron] = torch.load(os.path.join(data_dir, data_file))\n",
    "\n",
    "neurons = list(ablated_logits.keys())\n",
    "neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-70m into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "tokenizer = load_model('pythia-70m').tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Kalki Koechlin has gender; true class: female (female)\n",
      "\t[(' male', 0.76), (' female', 0.16), (' Male', 0.01), (' masculine', 0.01), (' gender', 0.01)]\n",
      "Prompt: Sofia Coppola has gender; true class: female (female)\n",
      "\t[(' male', 0.56), (' female', 0.35), (' gender', 0.01), (' feminine', 0.01), (' masculine', 0.0)]\n",
      "Prompt: Brenda Lee has gender; true class: female (female)\n",
      "\t[(' female', 0.63), (' male', 0.23), (' feminine', 0.01), (' woman', 0.01), (' gender', 0.01)]\n"
     ]
    }
   ],
   "source": [
    "# see results\n",
    "# TODO: do for each class\n",
    "n = 3\n",
    "for ix, example in enumerate(dataset.select(range(n))):\n",
    "    prompt = example['prompt'].split('.')[-1][1:]  # truncate the examples\n",
    "\n",
    "    logits = nominal_logits[ix, :].to(torch.float32)\n",
    "    probs = torch.nn.functional.softmax(logits, dim=0)\n",
    "\n",
    "    token_indices = torch.argsort(logits, descending=True)[:5]\n",
    "    predictions = tokenizer.batch_decode(token_indices)\n",
    "    prediction_probs = [round(p, 2) for p in probs[token_indices].tolist()]\n",
    "\n",
    "    print(f'Prompt: {prompt}; true class: {example[\"mapped_class\"]} ({example[\"class\"]})')\n",
    "    print(f'\\t{list(zip(predictions, prediction_probs))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do the above for each ablated neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.DataFrame(dataset)\n",
    "classes = dataset_df.mapped_class.unique().tolist()\n",
    "class_tokens = [tokenizer(f' {c}').input_ids[0] for c in classes]\n",
    "\n",
    "nominal_probs = torch.nn.functional.softmax(nominal_logits.to(torch.float32), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: female\n",
      "\tAccuracy: 0.50\n",
      "\tMean probability on correct token: 0.41\n",
      "Class: male\n",
      "\tAccuracy: 0.70\n",
      "\tMean probability on correct token: 0.57\n"
     ]
    }
   ],
   "source": [
    "# get accuracy for each class\n",
    "for c, c_token in zip(classes, class_tokens):\n",
    "    class_mask = (dataset_df.mapped_class == c).values\n",
    "    class_probs = nominal_probs[class_mask, c_token]\n",
    "\n",
    "    mean = class_probs.mean()\n",
    "    acc = (nominal_probs[class_mask, :].argmax(dim=1) == c_token).to(torch.float32).mean()\n",
    "\n",
    "    print(f'Class: {c}')\n",
    "    print(f'\\tAccuracy: {acc:.2f}')\n",
    "    print(f'\\tMean probability on correct token: {mean:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do the above for each ablated neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparprob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
